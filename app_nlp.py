import streamlit as st
import re
from collections import Counter
import docx
import nltk
from nltk.util import ngrams
from nltk.tokenize import sent_tokenize
from fpdf import FPDF
import io
import os

# Configuration de la page
st.set_page_config(layout="wide", initial_sidebar_state="expanded")
nltk.download('punkt')  # Assurez-vous de t√©l√©charger 'punkt'

# Appliquer des styles CSS personnalis√©s
st.markdown("""
    <style>
    [data-testid="stSidebarContent"] {
        color: grey;
        background-color: #FEFEFE;
    }
    .stApp {
        background-color: #EBF4F7;
    }
    .main-container {
        background-color: #FFFFFF;
        border-radius: 10px;
        font-family: 'Arial';
    }
    .col-container {
        background-color: #FFFBEC;
        border-radius: 10px;
    }
    div.stButton > button {
        background-color: #EFE9FF;
        color: black;
        padding: 10px 20px;
        border-radius: 10px;
        border: none;
    }
    .header-text {
        color: black;
    }
    </style>
""", unsafe_allow_html=True)

# Affichage de l'alerte et du champ de recherche en haut
st.markdown("""
    <style>
    .alert-band {
        background-color: #F6F6F6;
        padding: 10px;
        border-radius: 10px;
        align-items: center;
        justify-content: center;
        font-size: 13x;
        color: black;
        font-weight: bold;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    </style>
    <div class="alert-band">
        <span class="page-title-name-user">Yvell Mvoumbi</span> <span class="emoji">üîî</span>
    </div>
""", unsafe_allow_html=True)

# Champ de saisie pour la recherche de mots en haut de la page
search_word = st.text_input("Entrez un mot pour rechercher dans le texte", "")

# Barre lat√©rale
st.sidebar.title("Menu")
st.sidebar.markdown("""
    <div class="small-text">üìà Analyse s√©mantique des conf√©rences</div>
""", unsafe_allow_html=True)

# Affichage du titre principal
st.title("Analyse s√©mantique des Mots et Expressions Pertinents dans une Conf√©rence")
st.markdown("""
    <div class="page-title">üëã Bonjour, <span class="page-title-name-user">Yvell Mvoumbi</span></div>
""", unsafe_allow_html=True)

# Fonction pour charger le document Word et extraire le texte
def load_docx(file):
    doc = docx.Document(file)
    text = []
    for paragraph in doc.paragraphs:
        text.append(paragraph.text)
    return ' '.join(text)

# Fonction pour nettoyer et filtrer le texte
def preprocess_text(text):
    # Nettoyer le texte (supprimer les caract√®res non alphanum√©riques)
    return re.sub(r'\W+', ' ', text.lower())

# Extraire les bigrammes
def extract_bigrams(text, stop_words):
    words = [word for word in text.split() if word not in stop_words]
    bigrams = ngrams(words, 2)
    return Counter(bigrams).most_common(10)

# Compter les occurrences des mots individuels
def count_word_occurrences(text, stop_words):
    words = text.split()
    filtered_words = [word for word in words if word not in stop_words]
    return Counter(filtered_words).most_common(20)

# Segmenter les phrases
def simple_sent_tokenize(text):
    return re.split(r'(?<=[.!?]) +', text)

# Trouver les phrases contenant des mots pertinents
def find_trending_sentences(text, word_or_phrase):
    sentences = simple_sent_tokenize(text)
    relevant_sentences = [sentence for sentence in sentences if word_or_phrase in sentence.lower()]
    return relevant_sentences[:3]

# Ajouter la fonctionnalit√© de filtre pour rechercher des mots
def search_word_in_text(text, word):
    if word:
        st.write(f"**R√©sultats de la recherche pour le mot : '{word}'**")
        sentences_with_word = [sentence for sentence in simple_sent_tokenize(text) if word.lower() in sentence.lower()]
        if sentences_with_word:
            for sentence in sentences_with_word:
                st.write(f"- {sentence}")
        else:
            st.write("Aucune occurrence trouv√©e.")
    else:
        st.write("Veuillez entrer un mot √† rechercher.")

# Afficher les r√©sultats et retourner le texte pour le PDF
def display_results(word_counts, bigram_counts, text):
    result_text = ""  # Cette variable contiendra le texte pour le PDF
    st.subheader("Mots les plus fr√©quents et pertinents :")
    result_text += "Mots les plus fr√©quents et pertinents :\n"
    
    for word, count in word_counts:
        result_text += f"{word.capitalize()} ({count} occurrences)\n"
        st.write(f"**{word.capitalize()}** ({count} occurrences)")
        trending_sentences = find_trending_sentences(text, word)
        if trending_sentences:
            st.write("Exemples de phrases :")
            result_text += "Exemples de phrases :\n"
            for sentence in trending_sentences:
                result_text += f"- {sentence}\n"
                st.write(f"- {sentence}")
    
    st.subheader("Expressions compos√©es les plus fr√©quentes :")
    result_text += "\nExpressions compos√©es les plus fr√©quentes :\n"
    for bigram, count in bigram_counts:
        expression = ' '.join(bigram).capitalize()
        result_text += f"{expression} ({count} occurrences)\n"
        st.write(f"**{expression}** ({count} occurrences)")
        trending_sentences = find_trending_sentences(text, ' '.join(bigram))
        if trending_sentences:
            st.write("Exemples de phrases :")
            result_text += "Exemples de phrases :\n"
            for sentence in trending_sentences:
                result_text += f"- {sentence}\n"
                st.write(f"- {sentence}")
    
    return result_text  # Retourne le texte pour le PDF

# G√©n√©rer le fichier PDF √† partir des r√©sultats en utilisant une police prenant en charge l'UTF-8
def create_pdf(content):
    if content:  # V√©rifier que le contenu n'est pas None ou vide
        pdf = FPDF()
        pdf.add_page()
        
        # Chemin vers la police DejaVu
        font_path = os.path.join(os.path.dirname(__file__), 'DejaVuSansCondensed.ttf')
        if not os.path.exists(font_path):
            st.error("Fichier de police introuvable. Assurez-vous que 'DejaVuSansCondensed.ttf' est dans le bon r√©pertoire.")
            return None
        
        # Utilisation de DejaVu ou une autre police Unicode
        pdf.add_font('DejaVu', '', font_path, uni=True)
        pdf.set_font('DejaVu', '', 12)  # Utiliser la police DejaVu pour les caract√®res Unicode
        
        # Encoder le contenu en UTF-8
        for line in content.split('\n'):
            pdf.cell(200, 10, txt=line.encode('latin-1', 'replace').decode('latin-1'), ln=True)
        return pdf
    else:
        st.error("Le contenu est vide, impossible de g√©n√©rer le PDF.")

stop_words = set([
    # Articles et pronoms
    "le", "la", "les", "et", "de", "du", "des", "en", "pour", "avec",
    "sur", "par", "√†", "un", "une", "d", "l", "que", "qui", "est",
    "ce", "nous", "il", "elle", "ils", "elles", "ne", "pas", "mais",
    "aux", "dans", "on", "vous", "je", "qu", "si", "c", "n", "a", "√ßa",
    "y", "au", "plus", "fait", "va", "dire", "l√†", "ou", "alors", "√™tre",
    "peut", "tout", "quand", "m√™me", "sont", "tr√®s", "donc", "hui", "1",
    "intervenant", "aujourd", "√©t√©", "j'ai", "avez", "aussi", "s", "cette", "se", "ont", "m", "peu",
    "comme", "lorsque", "quand", "si", "puisque", "parce que", "afin que",
    "bien que", "quoique", "malgr√© que", "avant que", "sans que", "pour que",
    "depuis que", "d√®s que", "jusqu'√† ce que", "√† condition que",
    "pourvu que", "pendant que", "tandis que", "alors que", "o√π", "bien", "j", "ai",
    
    # Conjonctions de subordination
    "comme", "lorsque", "quand", "si", "puisque", "parce que", "afin que",
    "bien que", "quoique", "malgr√© que", "avant que", "sans que", "pour que",
    "depuis que", "d√®s que", "jusqu'√† ce que", "√† condition que",
    "pourvu que", "pendant que", "tandis que", "alors que", "o√π",
    
    # Verbes courants
    "avoir", "√™tre", "faire", "aller", "pouvoir", "vouloir", "devoir",
    "falloir", "venir", "prendre", "mettre", "savoir", "voir", "croire",
    "trouver", "donner", "parler", "passer", "penser", "aimer", "demander", "√©tait",
    
    # Mots de liaison
    "cependant", "toutefois", "d'ailleurs", "en effet", "de plus", "√©galement",
    "enfin", "donc", "ainsi", "puis", "ensuite", "par ailleurs", "autrefois",
    
    # Adjectifs possessifs
    "mon", "ton", "son", "notre", "votre", "leur", "ma", "ta", "sa",
    "mes", "tes", "ses", "nos", "vos", "leurs"
])

# Fonction principale pour lancer l'analyse
def main():
    # T√©l√©chargement du fichier
    uploaded_file = st.file_uploader("T√©l√©chargez un fichier Word (.docx)", type="docx")
    
    if uploaded_file is not None:
        # Bouton pour lancer l'analyse
        if st.button("Lancer l'analyse s√©mantique"):
            with st.spinner("Analyse en cours..."):
                # Charger et pr√©traiter le texte
                text = load_docx(uploaded_file)
                text_cleaned = preprocess_text(text)
                
                # Extraire les bigrammes et compter les mots
                bigram_counts = extract_bigrams(text_cleaned, stop_words)
                word_counts = count_word_occurrences(text_cleaned, stop_words)
                
                # Afficher les r√©sultats
                result_text = display_results(word_counts, bigram_counts, text)
                
                # Ex√©cuter la recherche du mot
                if search_word:
                    search_word_in_text(text, search_word)
            
            st.success("Analyse termin√©e avec succ√®s !")
            
            if result_text:  # V√©rifier que result_text n'est pas vide
                # Ajouter un bouton pour t√©l√©charger le fichier PDF avec les r√©sultats
                pdf = create_pdf(result_text)
                if pdf:
                    pdf_output = io.BytesIO()
                    pdf.output(pdf_output)
                    pdf_output.seek(0)
                    st.download_button(
                        label="T√©l√©charger les r√©sultats en PDF",
                        data=pdf_output,
                        file_name="resultat_analyse_semantique.pdf",
                        mime="application/pdf"
                    )
            else:
                st.error("Impossible de g√©n√©rer le PDF car le contenu est vide.")
    else:
        st.write("Veuillez t√©l√©charger un fichier Word pour analyser.")

# Appeler la fonction principale
if __name__ == "__main__":
    main()
